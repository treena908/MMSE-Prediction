{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"regression_expriemnts.ipynb","provenance":[{"file_id":"https://github.com/ThilinaRajapakse/pytorch-transformers-classification/blob/master/colab_quickstart.ipynb","timestamp":1583089406688}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5c1200661dbb4a8585e67ff5612716b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_193b65b1c62b48e6b109d1969c5fe231","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8570884667dc430fa7da451850f2a86d","IPY_MODEL_d558ca8e16dd4373a3903d3df3a2ed58"]}},"193b65b1c62b48e6b109d1969c5fe231":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8570884667dc430fa7da451850f2a86d":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_85a47bb8422b47b09ad552c20d15de8f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":442,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":442,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_91d8e1f886fe4fee8116d5ab365ab0b0"}},"d558ca8e16dd4373a3903d3df3a2ed58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4608e569a3764385b8b93f9d0889fa2a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 442/442 [00:01&lt;00:00, 404B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2004ad4fc49d4b2d99ec08291fd93a4d"}},"85a47bb8422b47b09ad552c20d15de8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"91d8e1f886fe4fee8116d5ab365ab0b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4608e569a3764385b8b93f9d0889fa2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2004ad4fc49d4b2d99ec08291fd93a4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28260fa033a1492abef6b88905e03596":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0353548f7f0646a18c42b12bafc60f17","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9a17f19f906d42f986456c234328cc51","IPY_MODEL_cd49d67f7efd479ba6bd1ae9595897c0"]}},"0353548f7f0646a18c42b12bafc60f17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a17f19f906d42f986456c234328cc51":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9a3b2178ef114090862388ccc26dd6ad","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e7ff07edca148f9ad8ef271c29e3ad8"}},"cd49d67f7efd479ba6bd1ae9595897c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6717f68b659b4c489bfb5f49300f18b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 725kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46544376a7f942cea6e19c545999844e"}},"9a3b2178ef114090862388ccc26dd6ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9e7ff07edca148f9ad8ef271c29e3ad8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6717f68b659b4c489bfb5f49300f18b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46544376a7f942cea6e19c545999844e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"MrIwJ5QDz-e9","outputId":"3386b0ee-d0bd-4af7-ded8-595b28f565b5","executionInfo":{"status":"ok","timestamp":1588813820648,"user_tz":300,"elapsed":9757,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":663}},"source":["!pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\r\u001b[K     |▋                               | 10kB 20.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 3.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 5.3MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 6.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 20.0MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.13.1)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 39.0MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 23.0MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: botocore<1.17.0,>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.16.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->transformers) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=e1d03013c167cce9eb3a2bc426247ceba63310aab0b3eb48facc8c4bca65a1ff\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0NE4g6D2fyTI","colab_type":"code","outputId":"9f1a64ca-9914-46ba-c8f9-ad4f8518da7f","executionInfo":{"status":"ok","timestamp":1588813835085,"user_tz":300,"elapsed":24182,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install wandb"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/c9/ebbcefa6ef2ba14a7c62a4ee4415a5fecef8fac5e4d1b4e22af26fd9fe22/wandb-0.8.35-py2.py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 11.9MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n","Collecting gql==0.2.0\n","  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/7e/19545324e83db4522b885808cd913c3b93ecc0c88b03e037b78c6a417fa8/sentry_sdk-0.14.3-py2.py3-none-any.whl (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 45.7MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n","Collecting watchdog>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n","\u001b[K     |████████████████████████████████| 102kB 11.7MB/s \n","\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n","\u001b[K     |████████████████████████████████| 460kB 39.0MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2020.4.5.1)\n","Collecting graphql-core<2,>=0.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n","Collecting pathtools>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n","\u001b[?25hCollecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n","Building wheels for collected packages: subprocess32, gql, watchdog, graphql-core, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=09b13cbdc747ade9d3bd912e411a309a0bd4d9ae3b7a89bf5123d417f5d99f63\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=83cd07435269194036391d109471ef6c61980ef2aa67e68d0b5f8510113f197d\n","  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=49036e5ebb48a2035c811971a6d5da54598637778a5e224256d7c9c353785e1a\n","  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n","  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=6bfd2bbe4422d21cfb128a5e92290471b4422eb810fe5066b3ea7cca3ef904f6\n","  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=e50bb40b0e0c1a68dec0b9784945c5b46b9aa0dc511263af52bb0a86d7f074de\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built subprocess32 gql watchdog graphql-core pathtools\n","Installing collected packages: subprocess32, graphql-core, gql, configparser, sentry-sdk, pathtools, watchdog, shortuuid, docker-pycreds, smmap, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.2 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.14.3 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.8.35 watchdog-0.10.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fNgX11KZf09T","colab_type":"code","outputId":"11a87bd0-ea3c-41aa-bd3f-fa12d48c2948","executionInfo":{"status":"ok","timestamp":1588813850106,"user_tz":300,"elapsed":39193,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!wandb login"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: 0f899bbf33dae82e8872c7b94e506e9e25177178\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ghtn49aGgXQM","colab_type":"code","outputId":"a50a3d6f-2be6-42b5-bc84-8a1e0645ae57","executionInfo":{"status":"ok","timestamp":1588813850888,"user_tz":300,"elapsed":39968,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import wandb\n","wandb.init(project=\"bert_ita_train\")"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://app.wandb.ai/flaviodipalo/bert_ita_train\" target=\"_blank\">https://app.wandb.ai/flaviodipalo/bert_ita_train</a><br/>\n","                Run page: <a href=\"https://app.wandb.ai/flaviodipalo/bert_ita_train/runs/1zorxk3v\" target=\"_blank\">https://app.wandb.ai/flaviodipalo/bert_ita_train/runs/1zorxk3v</a><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["W&B Run: https://app.wandb.ai/flaviodipalo/bert_ita_train/runs/1zorxk3v"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0YLoS0hWz-ch","outputId":"3013c722-dba1-4237-fe40-964cdb3273cd","executionInfo":{"status":"ok","timestamp":1588813850889,"user_tz":300,"elapsed":39963,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile utils.py \n","\n","# coding=utf-8\n","# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n","# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\" BERT classification fine-tuning: utilities to work with GLUE tasks \"\"\"\n","\n","from __future__ import absolute_import, division, print_function\n","\n","import csv\n","import logging\n","import os\n","import sys\n","from io import open\n","\n","from scipy.stats import pearsonr, spearmanr\n","from sklearn.metrics import matthews_corrcoef, f1_score\n","\n","from multiprocessing import Pool, cpu_count\n","from tqdm import tqdm\n","\n","logger = logging.getLogger(__name__)\n","csv.field_size_limit(2147483647)\n","\n","class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text_a, text_b=None, label=None,lang_id=None):\n","        \"\"\"Constructs a InputExample.\n","\n","        Args:\n","            guid: Unique id for the example.\n","            text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","            text_b: (Optional) string. The untokenized text of the second sequence.\n","            Only must be specified for sequence pair tasks.\n","            label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.label = label\n","        self.lang_id = lang_id\n","\n","\n","\n","class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, input_ids, input_mask, segment_ids, label_id,lang_id=None):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_id = label_id\n","        self.lang_id = lang_id\n","\n","\n","class DataProcessor(object):\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n","        raise NotImplementedError()\n","\n","    def get_labels(self):\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\n","        raise NotImplementedError()\n","\n","    @classmethod\n","    def _read_tsv(cls, input_file, quotechar=None):\n","        \"\"\"Reads a tab separated value file.\"\"\"\n","        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n","            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n","            lines = []\n","            for line in reader:\n","                if sys.version_info[0] == 2:\n","                    line = list(unicode(cell, 'utf-8') for cell in line)\n","                lines.append(line)\n","            return lines\n","\n","\n","class BinaryProcessor(DataProcessor):\n","    \"\"\"Processor for the binary data sets\"\"\"\n","\n","    def get_train_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._create_examples(\n","            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n","\n","    def get_dev_examples(self, data_dir):\n","        \"\"\"See base class.\"\"\"\n","        return self._create_examples(\n","            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n","\n","    def get_labels(self):\n","        \"\"\"See base class.\"\"\"\n","        return [\"0\", \"1\"]\n","\n","    def _create_examples(self, lines, set_type):\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\n","        examples = []\n","        for (i, line) in enumerate(lines):\n","            guid = \"%s-%s\" % (set_type, i)\n","            text_a = line[3]\n","            label = line[1]\n","            #lang_id = line[4]\n","            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label, lang_id=None))\n","        return examples\n","\n","\n","def convert_example_to_feature(example_row, pad_token=0,\n","sequence_a_segment_id=0, sequence_b_segment_id=1,\n","cls_token_segment_id=1, pad_token_segment_id=0,\n","mask_padding_with_zero=True):\n","\n","    example, label_map, max_seq_length, tokenizer, output_mode, cls_token_at_end, cls_token, sep_token, cls_token_segment_id, pad_on_left, pad_token_segment_id = example_row\n","\n","    tokens_a = tokenizer.tokenize(example.text_a)\n","\n","    tokens_b = None\n","    if example.text_b:\n","        tokens_b = tokenizer.tokenize(example.text_b)\n","        # Modifies `tokens_a` and `tokens_b` in place so that the total\n","        # length is less than the specified length.\n","        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n","    else:\n","        # Account for [CLS] and [SEP] with \"- 2\"\n","        if len(tokens_a) > max_seq_length - 2:\n","            tokens_a = tokens_a[:(max_seq_length - 2)]\n","\n","    # The convention in BERT is:\n","    # (a) For sequence pairs:\n","    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n","    #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n","    # (b) For single sequences:\n","    #  tokens:   [CLS] the dog is hairy . [SEP]\n","    #  type_ids:   0   0   0   0  0     0   0\n","    #\n","    # Where \"type_ids\" are used to indicate whether this is the first\n","    # sequence or the second sequence. The embedding vectors for `type=0` and\n","    # `type=1` were learned during pre-training and are added to the wordpiece\n","    # embedding vector (and position vector). This is not *strictly* necessary\n","    # since the [SEP] token unambiguously separates the sequences, but it makes\n","    # it easier for the model to learn the concept of sequences.\n","    #\n","    # For classification tasks, the first vector (corresponding to [CLS]) is\n","    # used as as the \"sentence vector\". Note that this only makes sense because\n","    # the entire model is fine-tuned.\n","    tokens = tokens_a + [sep_token]\n","    segment_ids = [sequence_a_segment_id] * len(tokens)\n","\n","    if tokens_b:\n","        tokens += tokens_b + [sep_token]\n","        segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n","\n","    if cls_token_at_end:\n","        tokens = tokens + [cls_token]\n","        segment_ids = segment_ids + [cls_token_segment_id]\n","    else:\n","        tokens = [cls_token] + tokens\n","        segment_ids = [cls_token_segment_id] + segment_ids\n","\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","    # tokens are attended to.\n","    input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n","\n","    # Zero-pad up to the sequence length.\n","    padding_length = max_seq_length - len(input_ids)\n","    if pad_on_left:\n","        input_ids = ([pad_token] * padding_length) + input_ids\n","        input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n","        segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n","    else:\n","        input_ids = input_ids + ([pad_token] * padding_length)\n","        input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n","        segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n","\n","    assert len(input_ids) == max_seq_length\n","    assert len(input_mask) == max_seq_length\n","    assert len(segment_ids) == max_seq_length\n","\n","    #lang_ids = [int(example.lang_id)]*max_seq_length\n","    #assert len(lang_ids) == max_seq_length\n","\n","    if output_mode == \"classification\":\n","        label_id = label_map[example.label]\n","    elif output_mode == \"regression\":\n","        label_id = float(example.label)\n","    else:\n","        raise KeyError(output_mode)\n","\n","    return InputFeatures(input_ids=input_ids,\n","                        input_mask=input_mask,\n","                        segment_ids=segment_ids,\n","                        label_id=label_id,\n","                        lang_id = None)\n","    \n","def convert_examples_to_features(examples, label_list, max_seq_length,\n","                                 tokenizer, output_mode,\n","                                 cls_token_at_end=False, pad_on_left=False,\n","                                 cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n","                                 sequence_a_segment_id=0, sequence_b_segment_id=1,\n","                                 cls_token_segment_id=1, pad_token_segment_id=0,\n","                                 mask_padding_with_zero=True,\n","                                 process_count=cpu_count() - 2):\n","    \"\"\" Loads a data file into a list of `InputBatch`s\n","        `cls_token_at_end` define the location of the CLS token:\n","            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n","            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n","        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n","    \"\"\"\n","\n","    label_map = {label : i for i, label in enumerate(label_list)}\n","    \n","    examples = [(example, label_map, max_seq_length, tokenizer, output_mode, cls_token_at_end, cls_token, sep_token, cls_token_segment_id, pad_on_left, pad_token_segment_id) for example in examples]\n","\n","    with Pool(process_count) as p:\n","        features = list(tqdm(p.imap(convert_example_to_feature, examples, chunksize=100), total=len(examples)))\n","\n","    return features\n","\n","\n","def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            tokens_b.pop()\n","\n","\n","processors = {\n","    \"binary\": BinaryProcessor\n","}\n","\n","output_modes = {\n","    \"binary\": \"classification\"\n","}\n","\n","GLUE_TASKS_NUM_LABELS = {\n","    \"binary\": 2\n","}\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Writing utils.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qYv4tGNs4Tg8","outputId":"1987ebef-5dc8-48b8-c528-7ac9fa69dcaa","executionInfo":{"status":"ok","timestamp":1588813881217,"user_tz":300,"elapsed":70286,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["!mkdir data\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VeXuXWylz7BD","colab":{}},"source":["from __future__ import absolute_import, division, print_function\n","\n","import glob\n","import logging\n","import os\n","import random\n","import json\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","import random\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm_notebook, trange\n","\n","\n","from transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer,\n","                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n","                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n","                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, \n","                                  DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer)\n","\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","from utils import (convert_examples_to_features,\n","                        output_modes, processors)\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","\n","\n","args = {\n","    'data_dir': 'data/',\n","    'model_type': 'distilbert',\n","    'model_name':'distilbert-base-uncased',\n","    #'model_name':'distilbert-base-multilingual-cased',\n","    #'model_type': 'xlm',\n","    #'model_name':'xlm-mlm-17-1280',\n","    \n","    'task_name': 'binary',\n","    'output_dir': 'outputs/',\n","    'cache_dir': 'cache/',\n","    'do_train': True,\n","    'do_eval': True,\n","    'fp16': False,\n","    'fp16_opt_level': 'O1',\n","    'max_seq_length': 128,\n","    #'output_mode': 'classification',\n","    'output_mode': 'regression',\n","    'train_batch_size': 4,\n","    'eval_batch_size': 4,\n","\n","    'gradient_accumulation_steps': 1,\n","    'num_train_epochs': 45,\n","    'weight_decay': 0,\n","    'learning_rate': 4e-5,\n","    'adam_epsilon': 1e-8,\n","    'warmup_steps': 0,\n","    'max_grad_norm': 1.0,\n","\n","    'logging_steps': 50,\n","    'evaluate_during_training': False,\n","    'save_steps': 2000,\n","    'eval_all_checkpoints': True,\n","\n","    'overwrite_output_dir': True,\n","    'reprocess_input_data': True,\n","}\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Uzr2RwGLz7BL","colab":{}},"source":["with open('args.json', 'w') as f:\n","    json.dump(args, f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ymjmIyOhz7BN","colab":{}},"source":["if os.path.exists(args['output_dir']) and os.listdir(args['output_dir']) and args['do_train'] and not args['overwrite_output_dir']:\n","    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args['output_dir']))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LAHYiiLMz7BP","colab":{}},"source":["MODEL_CLASSES = {\n","    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n","    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n","    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n","    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer), \n","    'distilbert': (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer)\n","}\n","\n","config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qm5AguwFz7BR","outputId":"1e23f125-2d3e-45cf-fd0c-8c9215c379cd","executionInfo":{"status":"ok","timestamp":1588813887858,"user_tz":300,"elapsed":76903,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5c1200661dbb4a8585e67ff5612716b6","193b65b1c62b48e6b109d1969c5fe231","8570884667dc430fa7da451850f2a86d","d558ca8e16dd4373a3903d3df3a2ed58","85a47bb8422b47b09ad552c20d15de8f","91d8e1f886fe4fee8116d5ab365ab0b0","4608e569a3764385b8b93f9d0889fa2a","2004ad4fc49d4b2d99ec08291fd93a4d","28260fa033a1492abef6b88905e03596","0353548f7f0646a18c42b12bafc60f17","9a17f19f906d42f986456c234328cc51","cd49d67f7efd479ba6bd1ae9595897c0","9a3b2178ef114090862388ccc26dd6ad","9e7ff07edca148f9ad8ef271c29e3ad8","6717f68b659b4c489bfb5f49300f18b8","46544376a7f942cea6e19c545999844e"]}},"source":["config = config_class.from_pretrained(args['model_name'], num_labels=1, finetuning_task=args['task_name'])\n","tokenizer = tokenizer_class.from_pretrained(args['model_name'])\n","#config = config_class(dropout=0.1, attention_dropout=0.1,seq_classif_dropout=0.2,num_labels=1)\n","#tokenizer = tokenizer_class()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:filelock:Lock 139992443848968 acquired on /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n","INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpn52gp9tc\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c1200661dbb4a8585e67ff5612716b6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=442, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json in cache at /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n","INFO:filelock:Lock 139992443848968 released on /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n","INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n","INFO:transformers.configuration_utils:Model config DistilBertConfig {\n","  \"_num_labels\": 1,\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"dim\": 768,\n","  \"do_sample\": false,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": \"binary\",\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_beams\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"qa_dropout\": 0.1,\n","  \"repetition_penalty\": 1.0,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"tie_weights_\": true,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:filelock:Lock 139992443847344 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp0g69gj4z\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28260fa033a1492abef6b88905e03596","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","INFO:filelock:Lock 139992443847344 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6oL9OuJPboQQ","colab_type":"code","colab":{}},"source":["ENGLISH = False ## used to chose between the english and italian dataset. \n","GENERATE_TRANSFER_LEARNING = False ## used to generate a dataframe based only on. \n","ONE_SHOT = False ## used to predict only based on one shot scenarios. \n","FINE_TUNING_ONLY = False ## only trains the classifier added on bert hidden neurons. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Xe4P94Bfz7Ba","colab":{}},"source":["task = args['task_name']\n","processor = processors[task]()\n","label_list = processor.get_labels()\n","num_labels = len(label_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xqr_fwM3z7Bd","colab":{}},"source":["def load_and_cache_examples(task, tokenizer, evaluate=False):\n","    processor = processors[task]()\n","    output_mode = args['output_mode']\n","    \n","    mode = 'dev' if evaluate else 'train'\n","    cached_features_file = os.path.join(args['data_dir'], f\"cached_{mode}_{args['model_name']}_{args['max_seq_length']}_{task}\")\n","    \n","    if os.path.exists(cached_features_file) and not args['reprocess_input_data']:\n","        logger.info(\"Loading features from cached file %s\", cached_features_file)\n","        features = torch.load(cached_features_file)\n","               \n","    else:\n","        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n","        label_list = processor.get_labels()\n","        examples = processor.get_dev_examples(args['data_dir']) if evaluate else processor.get_train_examples(args['data_dir'])\n","        features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n","            cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n","            cls_token=tokenizer.cls_token,\n","            sep_token=tokenizer.sep_token,\n","            cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n","            pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n","            pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0,\n","            process_count=2)\n","        \n","        logger.info(\"Saving features into cached file %s\", cached_features_file)\n","        torch.save(features, cached_features_file)\n","        \n","    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","\n","    #all_lang_ids = torch.tensor([f.lang_id for f in features], dtype=torch.long)\n","    \n","    if output_mode == \"classification\":\n","        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n","    elif output_mode == \"regression\":\n","        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n","\n","    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)#all_lang_ids)\n","    return dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oCul6vvCz7Bg","colab":{}},"source":["from torch.utils.data import SubsetRandomSampler\n","import numpy as np \n","def train(train_dataset, model, tokenizer,validation_split=None, shuffle_dataset=True):\n","    #train_sampler = RandomSampler(train_dataset)\n","    #train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n","\n","    dataset_size = len(train_dataset)\n","    indices = list(range(dataset_size))\n","    \n","    if shuffle_dataset :\n","      np.random.seed(100495)\n","      np.random.shuffle(indices)\n","    if validation_split is not None: \n","      split = int(np.floor(validation_split * dataset_size))\n","      train_indices, val_indices = indices[split:], indices[:split]\n","      train_sampler = SubsetRandomSampler(train_indices)\n","      valid_sampler = SubsetRandomSampler(val_indices)\n","      valid_dataloader = DataLoader(train_dataset, sampler=valid_sampler, batch_size=args['train_batch_size'])\n","    else: \n","      train_sampler = RandomSampler(train_dataset)\n","\n","    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n","\n","    t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n","    \n","    no_decay = ['bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n","    scheduler = scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args['warmup_steps'], num_training_steps = t_total)\n","    \n","    if args['fp16']:\n","        try:\n","            from apex import amp\n","        except ImportError:\n","            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n","        model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n","        \n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(train_dataset))\n","    logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n","    logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n","    logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","    logger.info(\" TIPO DEL DATASET: %s\", type(train_dataset))\n","\n","    global_step = 0\n","    tr_loss, logging_loss = 0.0, 0.0\n","\n","    if FINE_TUNING_ONLY: \n","      for name, param in model.named_parameters():\n","        if 'distilbert' in name: \n","          param.requires_grad = False\n","    \n","    model.zero_grad()\n","    train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n","    \n","  # italian language id. \n","\n","    # We reshape it to be of size (batch_size, sequence_length)\n","    for _ in train_iterator:\n","        \n","        ##TODO: loggare epoca e loss alla fine dell'epoca wandb.log({'epochs':global_step, 'loss':tr_loss / global_step})\n","\n","        epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\n","        valid_loss_list = [] \n","        train_loss_list = []\n","        for step, batch in enumerate(epoch_iterator):\n","            model.train()\n","            batch = tuple(t.to(device) for t in batch)\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      #'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n","                      'labels':         batch[3],\n","                      #'langs': batch[4] ## aggiunto per XLM \n","                      }\n","            \n","            outputs = model(**inputs)\n","            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n","            train_loss_list.append(loss.item())\n","            print(\"\\r%f\" % loss, end='')\n","\n","            if args['gradient_accumulation_steps'] > 1:\n","                loss = loss / args['gradient_accumulation_steps']\n","\n","            if args['fp16']:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n","                \n","            else:\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n","           \n","            train_loss_early = loss.item()\n","            tr_loss += loss.item()\n","            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n","                scheduler.step()  # Update learning rate schedule\n","                optimizer.step()\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if args['logging_steps'] > 0 and global_step % args['logging_steps'] == 0:\n","                    # Log metrics\n","                    if args['evaluate_during_training']:  # Only evaluate when single GPU otherwise metrics may not average well\n","                        results = evaluate(model, tokenizer)\n","\n","                    logging_loss = tr_loss\n","\n","                if args['save_steps'] > 0 and global_step % args['save_steps'] == 0:\n","                    # Save model checkpoint\n","                    output_dir = os.path.join(args['output_dir'], 'checkpoint-{}'.format(global_step))\n","                    if not os.path.exists(output_dir):\n","                        os.makedirs(output_dir)\n","                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","                    model_to_save.save_pretrained(output_dir)\n","                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n","\n","        #### EARLY STOPPING PART \n","        # clear lists to track next epoch\n","        if validation_split is not None: \n","\n","\n","          model.eval()\n","          eval_loss = 0.0\n","          tmp_eval_loss = 0.0\n","          nb_eval_steps = 0.0\n","          preds = None\n","          out_label_ids = None\n","          \n","          for batch in tqdm_notebook(valid_dataloader, desc=\"Validation\"):\n","            batch = tuple(t.to(device) for t in batch)\n","            with torch.no_grad():\n","                inputs = {'input_ids':      batch[0],\n","                          'attention_mask': batch[1],\n","                          'labels':         batch[3]}\n","                outputs = model(**inputs)\n","                tmp_eval_loss, logits = outputs[:2]\n","                valid_loss_list.append(tmp_eval_loss.item())\n","        #print(train_loss_list)\n","        #print(valid_loss_list)\n","\n","          wandb.log({'train_loss':np.mean(train_loss_list), 'valid_loss':np.mean(valid_loss_list)})\n","        else: \n","          wandb.log({'train_loss':np.mean(train_loss_list)})\n","        \"\"\"\n","              if preds is None:\n","                  preds = logits.detach().cpu().numpy()\n","                  out_label_ids = inputs['labels'].detach().cpu().numpy()\n","              else:\n","                  preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n","                  out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","          eval_loss = eval_loss / nb_eval_steps\n","          if args['output_mode'] == \"classification\":\n","              preds = np.argmax(preds, axis=1)\n","          \n","          \n","          # print training/validation statistics \n","          # calculate average loss over an epoch\n","          train_loss = np.average(train_losses)\n","          valid_loss = np.average(tmp_eval_loss)\n","          avg_train_losses.append(train_loss)\n","          avg_valid_losses.append(tmp_eval_loss)\n","          \n","          logger.info('[EARLY STOPPING INFO], training loss: %s, validation loss: %s', train_loss, validation_loss)\n","          # early_stopping needs the validation loss to check if it has decresed, \n","          # and if it has, it will make a checkpoint of the current model\n","          \n","          early_stopping(valid_loss, model)\n","          \n","          if early_stopping.early_stop:\n","              logger.info('EARLY STOPPING BREAKING CYCLE')\n","              return global_step, tr_loss / global_step\n","          \"\"\"\n","\n","\n","    return global_step, tr_loss / global_step"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tUvkEBZUz7Bk","colab":{}},"source":["from sklearn.metrics import mean_absolute_error,mean_squared_error, matthews_corrcoef, confusion_matrix, accuracy_score, f1_score, r2_score\n","from scipy.stats import pearsonr\n","def get_mismatched(labels, preds):\n","    mismatched = labels != preds\n","    examples = processor.get_dev_examples(args['data_dir'])\n","    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n","    \n","    return wrong\n","\n","def get_eval_report(labels, preds):\n","\n","    if args['output_mode'] == 'regression': \n","      rmse = np.sqrt(mean_squared_error(labels,preds))\n","      r_2 = r2_score(labels, preds)\n","      mae = mean_absolute_error(labels,preds)\n","      return {\n","          \"rmse\": rmse,\n","          \"r_2\": r_2,\n","          \"mae\": mae\n","\n","      }, get_mismatched(labels, preds)\n","\n","\n","    else: \n","      mcc = matthews_corrcoef(labels, preds)\n","      tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n","      accuracy = accuracy_score(labels, preds)\n","      f1 = f1_score(labels, preds)\n","\n","      return {\n","          \"mcc\": mcc,\n","          \"tp\": tp,\n","          \"tn\": tn,\n","          \"fp\": fp,\n","          \"fn\": fn, \n","          \"accuracy\": accuracy, \n","          \"f1\": f1, \n","      }, get_mismatched(labels, preds)\n","\n","def compute_metrics(task_name, preds, labels, ):\n","    assert len(preds) == len(labels)\n","    return get_eval_report(labels, preds)\n","\n","def evaluate(model, tokenizer, prefix=\"\"):\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_output_dir = args['output_dir']\n","\n","    results = {}\n","    EVAL_TASK = args['task_name']\n","\n","    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, evaluate=True)\n","    if not os.path.exists(eval_output_dir):\n","        os.makedirs(eval_output_dir)\n","\n","\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    preds = None\n","    out_label_ids = None\n","    for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n","        model.eval()\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        with torch.no_grad():\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[3]}\n","            outputs = model(**inputs)\n","            tmp_eval_loss, logits = outputs[:2]\n","\n","            eval_loss += tmp_eval_loss.mean().item()\n","        nb_eval_steps += 1\n","        if preds is None:\n","            preds = logits.detach().cpu().numpy()\n","            out_label_ids = inputs['labels'].detach().cpu().numpy()\n","        else:\n","            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n","            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    if args['output_mode'] == \"classification\":\n","        preds = np.argmax(preds, axis=1)\n","    elif args['output_mode'] == \"regression\":\n","        preds = np.squeeze(preds)\n","        print(preds)\n","    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n","    results.update(result)\n","\n","    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n","    with open(output_eval_file, \"w\") as writer:\n","        logger.info(\"***** Eval results {} *****\".format(prefix))\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return results, wrong"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHtYn7TRos6i","colab_type":"code","outputId":"0353b263-72d6-42c5-a693-ddee4e820803","executionInfo":{"status":"ok","timestamp":1588814521046,"user_tz":300,"elapsed":989,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["##DATA LOADING \n","\n","import pandas as pd\n","from tqdm import tqdm_notebook\n","import numpy as np \n","df = pd.read_pickle('/content/drive/My Drive/ADReSS/train/transcriptions.pickle')\n","pd.set_option('display.max_rows', 300)\n","print(list(df))\n","\n","\n","## shuffle the dataset \n","#df = df.sample(frac=1, random_state=100495).reset_index(drop=True)\n","\n","df = df[df.mmse != ' NA']\n","df = df[df.text != ' None']\n","df.dropna(inplace=True)\n","\n","df_cookie = df \n","df_cookie.head(200)\n","\n","\"\"\"\n","prefix = 'data/'\n","df = pd.read_pickle('/content/drive/My Drive/Thesis/interview_all_tasks_gra_mor_par_stringtext_mmse.pickle')\n","df = df[df.task.isin(['cookie'])]\n","df_en = df.sample(frac=1, random_state=100495).reset_index(drop=True)\n","\n","df = pd.read_pickle('/content/drive/My Drive/Thesis/italian_patients_152_translated.pickle')\n","df = df.sample(frac=1, random_state=100495).reset_index(drop=True)\n","\n","df['label'] = df.apply(lambda row: int(row.MMSE <24), axis = 1) \n","df_cookie = df \n","print(list(df_cookie))\n","\"\"\"\n","print(df_cookie)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['ID   ', ' age', ' gender ', 'mmse', 'label', 'text']\n","     ID      age  ... label                                               text\n","0    S079     59  ...     1  mhm . there 's a young boy & uh going in a coo...\n","1    S080     55  ...     1  okay he 's fallin ( g ) off a chair [ : stool ...\n","2    S081     69  ...     1  < well the kid > [ // ] the girl 's laughin ( ...\n","3    S082     66  ...     1  & =clears : throat well & =clears : throat & u...\n","5    S084     68  ...     1  alright . [ + ] I see the little boy stealing ...\n","6    S086     57  ...     1  there 's a little girl . and a little boy stan...\n","7    S087     70  ...     1  & hm < a lady > [ / ] a lady and her children ...\n","8    S089     65  ...     1  so she will find her . and xxx the mother wash...\n","9    S090     59  ...     1  mhm . [ + ] oh I see a part of the whole kitch...\n","10   S092     74  ...     1  the little boy is up on [ / ] & uh on this thi...\n","11   S093     68  ...     1  & uh well the children are climbing up and he ...\n","12   S094     64  ...     1  oh yes . [ + ] a little girl & a and the littl...\n","13   S095     74  ...     1  + < and I will tell you what 's & g +/ . [ + ]...\n","14   S096     71  ...     1  I see a tad bit . [ + ] and somebody is doin (...\n","15   S097     68  ...     1  an average home that looks very much like ours...\n","16   S100     68  ...     1  + < okay . [ + ] & uh there 's < a cook > [ //...\n","17   S101     56  ...     1  ( ... ) & um & t takin ( g ) some cookies . [ ...\n","18   S103     64  ...     1  the boy 's & uh fallin ( g ) off the stool . t...\n","19   S104     64  ...     1  okay , I see a boy in the cookie jar . I see h...\n","20   S107     77  ...     1  boy xxx in the cookie jar . [ + jar ] boy in a...\n","21   S108     61  ...     1  yes . [ + ] the water ? [ + ] well let 's see ...\n","22   S110     73  ...     1  now honey I & w & l & l & ha & w had it was in...\n","23   S111     66  ...     1  this is & uh a clause copy [ / ] copy c @ l by...\n","25   S116     62  ...     1  + < mhm . [ + ] & uh they [ // ] & s the cooki...\n","26   S118     77  ...     1  oh there 's a cookie jar and a youngster with ...\n","27   S122     62  ...     1  oh sure . [ + ] the little girl 's standing in...\n","28   S124     69  ...     1  ( . ) well the boy 's climbing a [ / ] & la a ...\n","29   S125     57  ...     1  mhm . [ + ] oh . [ + ] there 's a cookie jar ....\n","30   S126     73  ...     1  ( . ) I do n't see xxx . [ + ] ( loo ) ks like...\n","31   S127     72  ...     1  okay . [ + ] the lady 's washin ( g ) the dish...\n","32   S128     59  ...     1  well the poor mother 's a-doin ( g ) [ : doin ...\n","33   S129     65  ...     1  well the kid 's up takin ( g ) cookies out_of ...\n","34   S130     58  ...     1  a cookie jar . [ + gram ] and < the kid 's > [...\n","35   S132     61  ...     1  well start from [ / ] from the [ / ] the [ / ]...\n","37   S136     79  ...     1  well your sink is being run over , the water ....\n","38   S137     64  ...     1  & =clears : throat & hm the woman of the house...\n","39   S138     65  ...     1  the [ / ] the water 's flowing on the floor . ...\n","40   S139     69  ...     1  well the boy is in the cookie jar & =laughs . ...\n","41   S140     79  ...     1  + < well this boy is almost falling < out of t...\n","42   S141     65  ...     1  everything ? [ + ] happening ? [ + ] & hm mhm ...\n","43   S142     73  ...     1  & m & s boy & o over here standin ( g ) on the...\n","44   S143     60  ...     1  well little boy & =clears throat reachin ( g )...\n","45   S144     73  ...     1  well the kid 's standin ( g ) on a tilted stoo...\n","46   S145     77  ...     1  + < he must be pickin ( g ) apples here . ( be...\n","47   S148     74  ...     1  well she 's washin ( g ) dishes . he 's climbi...\n","48   S149     70  ...     1  I see the little boy 's down here +/ . + , get...\n","49   S150     58  ...     1  well the boy on the chair [ : stool ] [ * s : ...\n","50   S151     72  ...     1  the boy and the girl are playing and he 's gon...\n","51   S153     68  ...     1  oh you want me to & t & t on that ? [ + ] oh o...\n","52   S154     65  ...     1  you want me to tell you ? [ + ] okay & uh the ...\n","53   S156     71  ...     1  mhm . [ + ] well this one is in the cookie jar...\n","55   S002     62  ...     0  somebody 's getting cookies out_of the cookie ...\n","56   S003     69  ...     0  okay . [ + ] there 's a little boy and < he 's...\n","57   S004     71  ...     0  are you ready ? [ + ] & um well the sink is ov...\n","58   S005     74  ...     0  okay . [ + ] < many & dish or > [ // ] the mot...\n","59   S006     67  ...     0  ( . ) okay . [ + ] mother is drying the dishes...\n","60   S007     71  ...     0  boy & uh taking cookies out_of a cookie jar . ...\n","61   S009     67  ...     0  a boy is taking & uh cookies from the cookie j...\n","62   S011     70  ...     0  & =clears : throat a girl and a boy and a stoo...\n","63   S012     77  ...     0  okay . [ + ] & uh the mother is wiping a dish ...\n","64   S013     57  ...     0  okay . [ + ] & uh fellow falling off a stool ....\n","65   S015     70  ...     0  all of the action you see going on . [ + ] oka...\n","66   S016     63  ...     0  well the girl is watching the boy go into the ...\n","67   S017     65  ...     0  well I see the mother doing the dishes . < the...\n","68   S018     72  ...     0  all of the action . [ + ] & uh just go ahead a...\n","69   S019     57  ...     0  okay . [ + ] well the mother is drying the dis...\n","70   S020     58  ...     0  ( . ) boy 's fallin ( g ) off a stool . [ + gr...\n","71   S021     64  ...     0  & um the boy is taking & uh cookies . & uh the...\n","72   S024     73  ...     0  alright . [ + ] & um the mother is standing at...\n","73   S025     67  ...     0  okay . [ + ] water running out_of the sink . [...\n","74   S027     78  ...     0  look at the picture xxx ? [ + ] oh okay . [ + ...\n","75   S028     59  ...     0  + < washing +/ . washing dishes or wiping dish...\n","76   S029     72  ...     0  action . [ + ] + < alright . [ + ] a lady 's d...\n","77   S030     70  ...     0  okay the little boy is on a stool about to fal...\n","78   S032     57  ...     0  well the little girl is saying to be quiet to ...\n","79   S033     61  ...     0  mhm . [ + ] well the water 's running over on ...\n","80   S034     65  ...     0  well this & uh little boy is up on the stool t...\n","81   S035     66  ...     0  & hm . [ + ] touching lip . [ + gram ] \u0015_\u0015 rai...\n","82   S036     73  ...     0  well & uh for one thing this boy 's on the sto...\n","83   S038     57  ...     0  everything that I see going on . [ + ] okay . ...\n","84   S039     66  ...     0  I [ // ] do I start ? [ + ] the children are g...\n","85   S040     66  ...     0  well let 's see . [ + ] the boy is taking cook...\n","86   S041     57  ...     0  water 's pouring out_of the sink . and the wom...\n","87   S043     69  ...     0  can I start ? [ + ] there is a boy on the stoo...\n","88   S048     64  ...     0  okay is there a number of things ? [ + ] I_mea...\n","89   S049     65  ...     0  there 's a child reaching for a cookie . the c...\n","90   S051     65  ...     0  we 'll start with the girl . she 's going to t...\n","91   S052     67  ...     0  I see a boy & um getting < in the > [ / ] in t...\n","92   S055     70  ...     0  < the boy 's > [ // ] & uh the girl 's makin (...\n","93   S056     68  ...     0  & uh it 's & uh a kitchen scene . and the moth...\n","94   S058     69  ...     0  everything that 's going on okay . [ + ] & m m...\n","95   S059     57  ...     0  girl is reaching up . [ + gram ] the boy is [ ...\n","96   S061     60  ...     0  alright . [ + ] boy is getting into the cookie...\n","97   S062     64  ...     0  well , there 's a kid stealin ( g ) cookies fr...\n","98   S063     65  ...     0  okay . [ + ] the boy is standing up trying to ...\n","99   S064     61  ...     0  the kids are swiping some cookies and [ / ] & ...\n","100  S067     57  ...     0  okay . [ + ] the boy is taking cookies out_of ...\n","101  S068     50  ...     0  the & uh water 's running on the floor . boy '...\n","102  S070     72  ...     0  beginning now ? [ + ] boy is getting [ // ] re...\n","103  S071     74  ...     0  the kids are in the cookies . the stool is fal...\n","104  S072     75  ...     0  you mean right now tell you ? [ + ] & uh the b...\n","105  S073     61  ...     0  well ‡ the boy 's trying to get in this cookie...\n","106  S076     78  ...     0  mhm . [ + ] mhm a_lot_of things are happening ...\n","107  S077     77  ...     0  alright . [ + ] the little boy [ // ] girl 's ...\n","\n","[104 rows x 6 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mbLR38M6u7LQ","colab_type":"code","outputId":"595735a7-2de8-4427-c3b0-5e8a1eecf752","executionInfo":{"status":"ok","timestamp":1588814681814,"user_tz":300,"elapsed":888,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df_real_test = pd.read_pickle('/content/drive/My Drive/ADReSS/test/transcriptions.pickle')\n","print(list(df_real_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['ID', 'age', 'gender', 'mmse', 'label', 'text']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7lVE98bWgKBC","colab_type":"code","outputId":"e5ad4f9d-cd88-40ad-a027-c092a760c041","executionInfo":{"status":"ok","timestamp":1588814713149,"user_tz":300,"elapsed":896,"user":{"displayName":"Flavio Di Palo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhVxU3DdkvXgiAOjwde98YqlE5H01D0IUapqp1TsA=s64","userId":"14603068463594015861"}},"colab":{"base_uri":"https://localhost:8080/","height":833}},"source":["prediction_list = [27.317049,29.739937,28.880442,28.009893,26.9452, 10.853231\n",",24.062252,23.663597,25.826572,28.419922,23.670488,12.084503\n",",29.751371,24.49347,28.341967,23.590767,14.9259405, 29.708874\n",",29.746342,19.262901,29.748056,18.711681,14.511718,29.651728\n",",29.440687,21.529028,29.526741,17.706923,17.335941,22.870455\n",",11.807484,15.171249,9.462222,29.52437,23.633614,28.913319\n",",29.087828,24.971613,25.777164,29.667665,25.995598,29.544582\n",",22.855505,20.03634,28.33276,27.76795,29.596169,29.691006]\n","prediction_list = np.array(prediction_list)\n","original_list = np.array(df_real_test.mmse)\n","diff = prediction_list - original_list\n","\n","#print(diff)\n","#mae = [] \n","#for element in diff: \n","#  mae.append(abs(element))\n","#np.mean(mae)\n","\n","for index, row in df_real_test.iterrows():\n","    print('{};{}'.format(row['ID'].split()[0], prediction_list[index]) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["S160;27.317049\n","S161;29.739937\n","S162;28.880442\n","S163;28.009893\n","S164;26.9452\n","S165;10.853231\n","S166;24.062252\n","S167;23.663597\n","S168;25.826572\n","S169;28.419922\n","S170;23.670488\n","S171;12.084503\n","S172;29.751371\n","S173;24.49347\n","S174;28.341967\n","S175;23.590767\n","S176;14.9259405\n","S177;29.708874\n","S178;29.746342\n","S179;19.262901\n","S180;29.748056\n","S181;18.711681\n","S182;14.511718\n","S183;29.651728\n","S184;29.440687\n","S185;21.529028\n","S186;29.526741\n","S187;17.706923\n","S188;17.335941\n","S189;22.870455\n","S190;11.807484\n","S191;15.171249\n","S192;9.462222\n","S193;29.52437\n","S194;23.633614\n","S195;28.913319\n","S196;29.087828\n","S197;24.971613\n","S198;25.777164\n","S199;29.667665\n","S200;25.995598\n","S201;29.544582\n","S202;22.855505\n","S203;20.03634\n","S204;28.33276\n","S205;27.76795\n","S206;29.596169\n","S207;29.691006\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5f_yqLbOHtOa","colab_type":"code","colab":{}},"source":["mmse_list = []\n","for mmse in df_cookie.mmse: \n","  mmse_list.append(int(mmse))\n","print(np.mean(mmse_list))\n","\n","mean_list = [np.mean(mmse_list)]*len(mmse_list)\n","\n","from sklearn.metrics import mean_squared_error,mean_absolute_error\n","print(np.sqrt(mean_squared_error(mmse_list,mean_list)))\n","print(mean_absolute_error(mmse_list,mean_list))\n","import seaborn as sns, numpy as np\n","sns.set(); np.random.seed(0)\n","x = np.random.randn(100)\n","ax = sns.distplot(mmse_list,bins=30)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"slWS2OjXcFPu","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFySETLIcEV-","colab_type":"code","colab":{}},"source":["REAL_TEST = True   \n","\n","from collections import defaultdict\n","dict_list = defaultdict(list)\n","\n","n_folds = 5\n","test_percentage = 1/n_folds\n","df_len = len(df)\n","\n","for i in range(n_folds): \n","  !rm -r outputs\n","  !mkdir outputs \n","  ##TODO recupera cose. \n","  number_of_samples = int(df_len*test_percentage)\n","\n","  msk = np.random.rand(len(df)) > 0\n","\n","\n","  if not GENERATE_TRANSFER_LEARNING: \n","    msk[i*number_of_samples:(i+1)*number_of_samples] = False\n","\n","  #msk2 = np.random.rand(len(df)) > 0.7\n","  #msk = np.array(msk) & np.array(msk2)\n","  df_cookie.sample(frac=1, random_state=1).reset_index(drop=True)\n","  if not REAL_TEST: \n","    train_ = df_cookie[msk]\n","    test_ = df_cookie[~msk]\n","\n","    train_df = pd.DataFrame({\n","        'id':range(len(train_)),\n","        'label':train_.mmse,\n","        'alpha':['a']*train_.shape[0],\n","        'text': train_.text,\n","        #'lang': int(tokenizer.lang2id['en'])\n","    })\n","    \n","    #dev_df = pd.DataFrame({\n","    #    'id':range(len(test_)),\n","    #    'label':test_.mmse,\n","    #    'alpha':['a']*test_.shape[0],\n","    #    'text': test_.text,\n","        #'lang': int(tokenizer.lang2id['it'])\n","    #})\n","\n","  else: \n","    train_df = pd.DataFrame({\n","        'id':range(len(df_cookie)),\n","        'label':df_cookie.mmse,\n","        'alpha':['a']*df_cookie.shape[0],\n","        'text': df_cookie.text,\n","        #'lang': int(tokenizer.lang2id['en'])\n","    })\n","\n","    dev_df = pd.DataFrame({\n","        'id':range(len(df_real_test)),\n","        'label':df_real_test.mmse,\n","        'alpha':['a']*df_real_test.shape[0],\n","        'text': df_real_test.text,\n","        #'lang': int(tokenizer.lang2id['it'])\n","    })\n","\n","\n","  dev_df.to_csv('data/dev.tsv', sep='\\t', index=False, header=False, columns=dev_df.columns)\n","  train_df.to_csv('data/train.tsv', sep='\\t', index=False, header=False, columns=train_df.columns)\n","\n","  if args['do_train']:\n","    train_dataset = load_and_cache_examples(task, tokenizer)\n","    \n","    ## chose a pretrained model \n","    #model = model_class.from_pretrained(args['model_name'])\n","    \n","    ## the model is not pretrained \n","    model = model_class(config)\n","\n","    model.to(device);\n","    if not ONE_SHOT: \n","      global_step, tr_loss = train(train_dataset, model, tokenizer)\n","      logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n","\n","  if args['do_train']:\n","    if not os.path.exists(args['output_dir']):\n","            os.makedirs(args['output_dir'])\n","    logger.info(\"Saving model checkpoint to %s\", args['output_dir'])\n","    \n","    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","    \n","    if GENERATE_TRANSFER_LEARNING: \n","      model_to_save.save_pretrained('./drive/My Drive/Thesis/xlm_english_trained/')\n","      tokenizer.save_pretrained('./drive/My Drive/Thesis/xlm_english_trained/')\n","    else:\n","      model_to_save.save_pretrained(args['output_dir'])\n","      tokenizer.save_pretrained(args['output_dir'])\n","      \n","    torch.save(args, os.path.join(args['output_dir'], 'training_args.bin'))\n","    results = {}\n","    if GENERATE_TRANSFER_LEARNING: \n","      logger.info('STOPPING TRAINING, DATASET GENERATED')\n","      break \n","\n","    if args['do_eval']:\n","        checkpoints = [args['output_dir']]\n","        if args['eval_all_checkpoints']:\n","            checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args['output_dir'] + '/**/' + WEIGHTS_NAME, recursive=True)))\n","            logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split('-')[-1] if len(checkpoints) > 1 else \"\"\n","            model = model_class.from_pretrained(checkpoint)\n","            model.to(device)\n","            result, wrong_preds = evaluate(model, tokenizer, prefix=global_step)\n","            result = dict((k + '_{}'.format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","\n","            for k, v in results.items():\n","              try: \n","                dict_list[k].append(v)\n","              except Exception as e: \n","                print(e)\n","  if REAL_TEST: \n","    break \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3JhQ0caTYJd","colab_type":"code","colab":{}},"source":["from google.colab import output\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n","\n","\n","\n","list_files = [27.317049,  29.739937 , 28.880442 , 28.009893,  26.9452  ,  10.853231,\n"," 24.062252,  23.663597 , 25.826572  28.419922  23.670488  12.084503\n"," 29.751371  24.49347   28.341967  23.590767  14.9259405 29.708874\n"," 29.746342  19.262901  29.748056  18.711681  14.511718  29.651728\n"," 29.440687  21.529028  29.526741  17.706923  17.335941  22.870455\n"," 11.807484  15.171249   9.462222  29.52437   23.633614  28.913319\n"," 29.087828  24.971613  25.777164  29.667665  25.995598  29.544582\n"," 22.855505  20.03634   28.33276   27.76795   29.596169  29.691006 ]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1On6YjIULf7v","colab":{}},"source":["print(dict_list)\n","for k in dict_list:\n","  print(k, np.mean(dict_list[k]))"],"execution_count":0,"outputs":[]}]}